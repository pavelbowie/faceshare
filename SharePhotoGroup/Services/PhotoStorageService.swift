//
//  PhotoStorageService.swift
//  SharePhotoGroup
//
//  Created by Pavel Mac on 29/04/25
//

import CoreData
import UIKit
import Combine
import Vision

class PhotoStorageService: ObservableObject {
    
    private let context: NSManagedObjectContext
    private let faceLabelingService: FaceLabelingService
    @Published var photos: [ReceivedPhotoModel] = []
    
    init(context: NSManagedObjectContext, faceLabelingService: FaceLabelingService) {
        self.context = context
        self.faceLabelingService = faceLabelingService
        loadPhotos()
    }
    
    func savePhoto(_ image: UIImage, senderName: String?, senderAvatar: UIImage?, recognizedFaces: [RecognizedFace]?) async {
        print("üì• –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–æ—Ç–æ...")
        print("   üìù –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Ñ–æ—Ç–æ:")
        print("   - –û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å: \(senderName ?? "–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω")")
        print("   - –ê–≤–∞—Ç–∞—Ä: \(senderAvatar != nil ? "–µ—Å—Ç—å" : "–Ω–µ—Ç")")
        print("   - –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –ª–∏—Ü–∞: \(recognizedFaces?.count ?? 0)")

        let photo = ReceivedPhotoEntity(context: context)
        let uuid = UUID()
        photo.id = uuid.uuidString
        photo.dateReceived = Date()
        photo.senderName = senderName
        
        // –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–≤–∞—Ç–∞—Ä–∫—É —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∫–∞—á–µ—Å—Ç–≤–æ–º
        if let avatar = senderAvatar {
            if let avatarData = avatar.jpegData(compressionQuality: 1.0) {
                photo.senderAvatar = avatarData
                print("üì∏ –ê–≤–∞—Ç–∞—Ä–∫–∞ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (—Ä–∞–∑–º–µ—Ä: \(avatarData.count) –±–∞–π—Ç)")
            } else {
                print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å –∞–≤–∞—Ç–∞—Ä–∫—É –≤ JPEG")
                photo.senderAvatar = nil
            }
        } else {
            photo.senderAvatar = nil
            print("‚ö†Ô∏è –ê–≤–∞—Ç–∞—Ä–∫–∞ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç")
        }
        
        if let imageData = image.jpegData(compressionQuality: 1.0) {
            photo.imageData = imageData
            print("üì∏ –û—Å–Ω–æ–≤–Ω–æ–µ —Ñ–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ (—Ä–∞–∑–º–µ—Ä: \(imageData.count) –±–∞–π—Ç)")
            
            // –ï—Å–ª–∏ –ø–µ—Ä–µ–¥–∞–Ω—ã —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –ª–∏—Ü–∞, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ö
            if let faces = recognizedFaces {
                print("üéØ –°–æ—Ö—Ä–∞–Ω—è–µ–º \(faces.count) —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã—Ö –ª–∏—Ü")
                for face in faces {
                    print("üß† –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª–∏—Ü–æ: \(face.name ?? "Unknown"), confidence: \(face.confidence), source: \(face.source)")
                    let faceEntity = RecognizedFaceEntity(context: context)
                    faceEntity.name = face.name
                    faceEntity.confidence = face.confidence
                    faceEntity.source = face.source.rawValue
                    photo.addToRecognizedFaces(faceEntity)
                    
                    // –ï—Å–ª–∏ –ª–∏—Ü–æ –∏–∑ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ —Ñ–æ—Ç–æ, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ –≤ FaceLabelingService
                    if face.source == .peer {
                        // –ü–æ–ª—É—á–∞–µ–º embedding –¥–ª—è –ª–∏—Ü–∞
                        if let faceImage = extractFaceImage(from: image, face: face) {
                            do {
                                let embedding = try faceLabelingService.faceEmbeddingService.getEmbedding(for: faceImage)
                                faceLabelingService.addPeerFace(embedding: embedding, name: face.name, from: "peer")
                                print("‚úÖ –õ–∏—Ü–æ –∏–∑ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ —Ñ–æ—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ FaceLabelingService: \(face.name ?? "Unknown")")
                            } catch {
                                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å embedding –¥–ª—è –ª–∏—Ü–∞ –∏–∑ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ —Ñ–æ—Ç–æ: \(error)")
                            }
                        }
                    }
                }
            } else {
                // –ï—Å–ª–∏ –ª–∏—Ü–∞ –Ω–µ –ø–µ—Ä–µ–¥–∞–Ω—ã, –ø—Ä–æ–±—É–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∏—Ö
                if let faces = await detectFacesAndCompareWithContacts(in: image) {
                    print("üéØ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü: \(faces.count)")
                    for face in faces {
                        print("üß† –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –ª–∏—Ü–æ: \(face.name), confidence: \(face.confidence), source: \(face.source)")
                        let faceEntity = RecognizedFaceEntity(context: context)
                        faceEntity.name = face.name
                        faceEntity.confidence = face.confidence
                        faceEntity.source = face.source.rawValue
                        photo.addToRecognizedFaces(faceEntity)
                        
                        // –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–µ –ª–∏—Ü–∞ –≤ FaceLabelingService
                        if let faceImage = extractFaceImage(from: image, face: face) {
                            do {
                                let embedding = try faceLabelingService.faceEmbeddingService.getEmbedding(for: faceImage)
                                faceLabelingService.addPeerFace(embedding: embedding, name: face.name, from: "peer")
                                print("‚úÖ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–µ –ª–∏—Ü–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ FaceLabelingService: \(face.name ?? "Unknown")")
                            } catch {
                                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å embedding –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ –ª–∏—Ü–∞: \(error)")
                            }
                        }
                    }
                } else {
                    print("‚ö†Ô∏è –õ–∏—Ü–∞ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã –∏–ª–∏ –Ω–µ —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω—ã")
                }
            }
            
            do {
                try context.save()
                print("‚úÖ –§–æ—Ç–æ –∏ –ª–∏—Ü–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ Core Data")
                print("   - ID —Ñ–æ—Ç–æ: \(photo.id ?? "–Ω–µ–∏–∑–≤–µ—Å—Ç–µ–Ω")")
                print("   - –î–∞—Ç–∞: \(photo.dateReceived?.description ?? "–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞")")
                print("   - –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏—Ü: \(photo.recognizedFaces?.count ?? 0)")
                loadPhotos()
            } catch {
                print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —Ñ–æ—Ç–æ: \(error)")
            }
        } else {
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ –≤ JPEG")
        }
    }
    
    func loadPhotos() {
        print("üì¶ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ñ–æ—Ç–æ –∏–∑ Core Data...")
        let request: NSFetchRequest<ReceivedPhotoEntity> = ReceivedPhotoEntity.fetchRequest()
        request.sortDescriptors = [NSSortDescriptor(keyPath: \ReceivedPhotoEntity.dateReceived, ascending: false)]
        
        do {
            let entities = try context.fetch(request)
            print("üì∑ –ù–∞–π–¥–µ–Ω–æ —Ñ–æ—Ç–æ: \(entities.count)")
            
            let loadedPhotos = entities.map { entity in
                var photo = ReceivedPhotoModel(
                    id: UUID(uuidString: entity.id ?? "") ?? UUID(),
                    image: entity.imageData.flatMap(UIImage.init),
                    dateReceived: entity.dateReceived,
                    recognizedFaces: [],
                    senderName: entity.senderName,
                    senderAvatar: nil,
                    isShared: entity.isShared,
                    isFavorite: entity.isFavorite
                )
                
                // –ó–∞–≥—Ä—É–∂–∞–µ–º –∞–≤–∞—Ç–∞—Ä–∫—É –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è
                if let avatarData = entity.senderAvatar {
                    print("üì∏ –ù–∞–π–¥–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∞–≤–∞—Ç–∞—Ä–∫–∏ –¥–ª—è —Ñ–æ—Ç–æ \(entity.id ?? "unknown") (—Ä–∞–∑–º–µ—Ä: \(avatarData.count) –±–∞–π—Ç)")
                    if let avatar = UIImage(data: avatarData) {
                        photo.senderAvatar = avatar
                        print("‚úÖ –ê–≤–∞—Ç–∞—Ä–∫–∞ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                    } else {
                        print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ–∑–¥–∞—Ç—å UIImage –∏–∑ –¥–∞–Ω–Ω—ã—Ö –∞–≤–∞—Ç–∞—Ä–∫–∏")
                    }
                }
                
                if let faces = entity.recognizedFaces as? Set<RecognizedFaceEntity> {
                    photo.recognizedFaces = faces.map { face in
                        print("üë§ –õ–∏—Ü–æ: \(face.name ?? "Unknown"), confidence: \(face.confidence)")
                        return RecognizedFace(
                            name: face.name ?? "Unknown",
                            confidence: face.confidence,
                            source: LabelSource(rawValue: face.source ?? "") ?? .peer
                        )
                    }
                } else {
                    print("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –ª–∏—Ü–∞ –¥–ª—è —Ñ–æ—Ç–æ")
                }
                
                return photo
            }
            
            DispatchQueue.main.async {
                self.photos = loadedPhotos
                print("‚úÖ –§–æ—Ç–æ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –≤ UI. –í—Å–µ–≥–æ: \(loadedPhotos.count)")
            }
        } catch {
            print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–æ—Ç–æ: \(error)")
            DispatchQueue.main.async {
                self.photos = []
            }
        }
    }
    
    func deletePhoto(_ photo: ReceivedPhotoModel) {
        print("üóëÔ∏è –£–¥–∞–ª—è–µ–º —Ñ–æ—Ç–æ: \(photo.id)")
        let request: NSFetchRequest<ReceivedPhotoEntity> = ReceivedPhotoEntity.fetchRequest()
        request.predicate = NSPredicate(format: "id == %@", photo.id.uuidString)
        do {
            let results = try context.fetch(request)
            if let entity = results.first {
                context.delete(entity)
                try context.save()
                print("‚úÖ –§–æ—Ç–æ —É–¥–∞–ª–µ–Ω–æ")
                loadPhotos()
            } else {
                print("‚ö†Ô∏è –§–æ—Ç–æ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            }
        } catch {
            print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ —Ñ–æ—Ç–æ: \(error)")
        }
    }
    private func detectFacesAndCompareWithContacts(in image: UIImage) -> [RecognizedFace]? {
        print("üîç –ó–∞–ø—É—Å–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –ª–∏—Ü...")
        let faceImage = cropFirstDetectedFace(from: image) ?? cropCenterFace(from: image)
        do {
            let embedding = try faceLabelingService.faceEmbeddingService.getEmbedding(for: faceImage)
            print("üß¨ Embedding –ø–æ–ª—É—á–µ–Ω. –î–ª–∏–Ω–∞: \(embedding.count)")
            
            // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ª–∏—Ü–∞
            let knownFaces = faceLabelingService.getKnownFaces()
            print("üìö –ò–∑–≤–µ—Å—Ç–Ω—ã—Ö –ª–∏—Ü –≤ –±–∞–∑–µ: \(knownFaces.count)")
            
            if let match = faceLabelingService.findMatch(for: embedding) {
                if let name = match.name {
                    print("‚úÖ –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ: \(name), confidence: \(match.confidence)")
                    if match.confidence > 0.3 {
                        print("‚úÖ –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–π–¥–µ–Ω–æ: \(name), confidence: \(match.confidence). –î–æ–±–∞–≤–ª—è—é —Ñ–æ—Ç–æ!")
                        return [RecognizedFace(name: name, confidence: match.confidence, source: match.source)]
                    } else {
                        print("‚ö†Ô∏è –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –Ω–∏–∑–∫–æ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é: \(match.confidence)")
                    }
                }
            } else {
                print("‚ùå –°–æ–≤–ø–∞–¥–µ–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            }
        } catch {
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å embedding: \(error)")
        }
        return nil
    }
    
    private func cropFirstDetectedFace(from image: UIImage) -> UIImage? {
        guard let cgImage = image.cgImage else { return nil }
        let request = VNDetectFaceRectanglesRequest()
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        do {
            try handler.perform([request])
            guard let results = request.results as? [VNFaceObservation], let firstFace = results.first else { return nil }
            let boundingBox = firstFace.boundingBox
            let width = CGFloat(cgImage.width)
            let height = CGFloat(cgImage.height)
            let rect = CGRect(
                x: boundingBox.origin.x * width,
                y: (1 - boundingBox.origin.y - boundingBox.height) * height,
                width: boundingBox.width * width,
                height: boundingBox.height * height
            ).integral
            guard let faceCgImage = cgImage.cropping(to: rect) else { return nil }
            return UIImage(cgImage: faceCgImage)
        } catch {
            print("–û—à–∏–±–∫–∞ Vision face detection: \(error)")
            return nil
        }
    }
    
    private func cropCenterFace(from image: UIImage) -> UIImage {
        let width = image.size.width
        let height = image.size.height
        let cropWidth = width * 0.6
        let cropHeight = height * 0.6
        let cropRect = CGRect(
            x: (width - cropWidth) / 2,
            y: (height - cropHeight) / 2,
            width: cropWidth,
            height: cropHeight
        )
        guard let cgImage = image.cgImage?.cropping(to: cropRect) else { return image }
        return UIImage(cgImage: cgImage)
    }
    
    private func extractFaceImage(from image: UIImage, face: RecognizedFace) -> UIImage? {
        guard let cgImage = image.cgImage else { return nil }
        
        let request = VNDetectFaceRectanglesRequest()
        let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])
        
        do {
            try handler.perform([request])
            if let results = request.results as? [VNFaceObservation],
               let firstFace = results.first {
                let boundingBox = firstFace.boundingBox
                let x = boundingBox.origin.x * CGFloat(cgImage.width)
                let y = (1 - boundingBox.origin.y - boundingBox.height) * CGFloat(cgImage.height)
                let width = boundingBox.width * CGFloat(cgImage.width)
                let height = boundingBox.height * CGFloat(cgImage.height)
                
                if let croppedCGImage = cgImage.cropping(to: CGRect(x: x, y: y, width: width, height: height)) {
                    return UIImage(cgImage: croppedCGImage)
                }
            }
        } catch {
            print("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ª–∏—Ü–∞: \(error)")
        }
        return nil
    }
}
